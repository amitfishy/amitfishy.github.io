[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Amit Sinha",
    "section": "",
    "text": "About Me\n\nHello! My name is Amit Sinha and I’m currently in the final year of my PhD at McGill University under the supervision of Prof. Aditya Mahajan. I’ve also previously worked with Matthieu Geist, Jayakumar Subramanium and Sarath Chandar.\n\nAffiliations: Mila, CIM, GERAD\n\n\nResearch Interests\n\nMy current research interests are centered around reinforcement learning for partially observable systems and multi-agent team-based systems.\n\n\nIn other words, I consider how a complicated amalgam of information used by an automated decision making agent can be reduced to smaller, simpler and more efficient blocks of information; and subsequently how to use these efficient blocks of information to learn automated decision making strategies that satisfy some pre-defined utility.\n\n\n\nRecent News\n\nDec 2024: Attending NeurIPS 2024.\nDec 2024: Attending CDC 2024.\nSep 2024: Our paper: Periodic agent-state based Q-learning (PASQL) for POMDPs was accepted in NeurIPS 2024 in Vancouver!\nJul 2024: Our tutorial paper: Agent-state based policies in POMDPs: Beyond belief-state MDPs was accepted in CDC 2024 in Milan, Italy!"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact Me",
    "section": "",
    "text": "If you’re interested in a general discussion or career related opportunities, please send me an email!"
  },
  {
    "objectID": "articles.html",
    "href": "articles.html",
    "title": "Featured publications",
    "section": "",
    "text": "Featured publications\n\n\n\n    \n      Periodic agent-state based Q-learning for POMDPs\n      \n        (arxiv)\n      \n      \n        (pdf)\n      \n      \n      \n      Amit Sinha, Matthieu Geist, and Aditya Mahajan\n      \n       \n        Conference on Neural Information Processing Systems (Neurips), \n      \n      \n      \n      \n      Dec 2024.\n      \n      \n      \n    \n\n    \n      Agent-state based policies in POMDPs: Beyond belief-state MDPs\n      \n      \n        (pdf)\n      \n      \n      \n      Amit Sinha and Aditya Mahajan\n      \n       \n        IEEE Conference on Decision and Control (CDC), \n      \n      \n      \n      \n      Dec 2024.\n      \n      \n      \n    \n\n    \n      Approximate information state for approximate planning and reinforcement learning in partially observed systems\n      \n      \n        (pdf)\n      \n      \n        (code)\n      \n      \n      Jayakumar Subramanian, Amit Sinha, Raihan Seraj, and Aditya Mahajan\n      \n       \n        Journal of Machine Learning Research, \n      \n       \n        vol. 23,\n      \n       \n        no. 12,\n      \n       \n        pp. 1-83,\n      \n      Feb 2022.\n      \n      \n      \n        URL: https://www.jmlr.org/papers/v23/20-1165.html\n      \n    \n\n\n\nNo matching items\n\n\n\n\nList of other publications\n\n\n\n    \n      Asymmetric Actor Critic with Approximate Information State\n      \n      \n        (pdf)\n      \n      \n      \n      Amit Sinha and Aditya Mahajan\n      \n       \n        IEEE Conference on Decision and Control (CDC), \n      \n      \n      \n      \n      Dec 2023.\n      \n      \n      \n    \n\n    \n      Dealing With Non-stationarity in Decentralized Cooperative Multi-Agent Deep Reinforcement Learning via Multi-Timescale Learning\n      \n      \n        (pdf)\n      \n      \n      \n      Hadi Nekoei, Akilesh Badrinaaraayanan, Amit Sinha, Mohammad Amini, Janarthanan Rajendran, Aditya Mahajan, and Sarath Chandar\n      \n       \n        Conference on Lifelong Learning Agents (CoLLA), \n      \n      \n      \n      \n      Aug 2023.\n      \n      \n      \n    \n\n    \n      Approximate information state based convergence analysis of recurrent Q-learning\n      \n        (arxiv)\n      \n      \n        (pdf)\n      \n      \n      \n      Erfan Seyedsalehi, Nima Akbarzadeh, Amit Sinha, and Aditya Mahajan\n      \n       \n        European Workshop on Reinforcement Learning, \n      \n      \n      \n      \n      Jun 2023.\n      \n      \n      \n    \n\n    \n      Robustness and sample complexity of model-based MARL for general-sum Markov games\n      \n      \n        (pdf)\n      \n      \n      \n      Jayakumar Subramanian, Amit Sinha, and Aditya Mahajan\n      \n       \n        Dynamic Games and Application, \n      \n      \n      \n       \n        pp. 56-88,\n      \n      Mar 2023.\n      \n      \n        DOI: 10.1007/s13235-023-00490-2\n      \n      \n    \n\n    \n      Robustness of Markov perfect equilibrium to model approximations in general-sum dynamic games\n      \n      \n        (pdf)\n      \n      \n      \n      Jayakumar Subramanian, Amit Sinha, and Aditya Mahajan\n      \n       \n        Indian Control Conference, \n      \n      \n      \n      \n      Dec 2021.\n      \n      \n      \n    \n\n    \n      An Approach Towards Automated Navigation of Vehicles using Overhead Cameras\n      \n      \n        (pdf)\n      \n      \n      \n      V. Sri Chakra Kumar, Amit Sinha, Pratheek P. Mallya, and Nutanlata Nath\n      \n       \n        IEEE International Conference on Computational Intelligence and Computing Research, \n      \n      \n      \n      \n      Dec 2017.\n      \n      \n      \n    \n\n\n\nNo matching items\n\n\n\nMaster’s thesis\n\nReinforcement learning in partially observable environments using approximate information state (pdf)  Amit Sinha  McGill University, Dec 2021."
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum vitae",
    "section": "",
    "text": "Download my CV here!"
  }
]